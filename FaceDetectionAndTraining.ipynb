{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Regonition:\n",
    "The face recognition code consists of three main steps:\n",
    "1. Collecting or creating dataset of images of the user\n",
    "2. Training the machine on the basis of that dataset and creating a model\n",
    "3. Using the created model machine will recognize the face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries or modules\n",
    "import cv2,os\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your Id:1\n"
     ]
    }
   ],
   "source": [
    "# Creating dataset by taking pictures through webcam\n",
    "detect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "cam=cv2.VideoCapture(0) # the parameter 0 is passed to open default camera in your computer\n",
    "Id=input(\"Enter your Id:\")\n",
    "sample=0\n",
    "while True:\n",
    "    ret, img = cam.read()\n",
    "    im=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # this will change the captured image into grayscale\n",
    "    faces=detect.detectMultiScale(im)\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(im, (x,y), (x+w,y+h), (0,255,0)) # form a rectangle around the face detecting live on webcam\n",
    "        sample=sample+1 # incrementing the sample value\n",
    "        cv2.imwrite('data/user.'+Id+'.'+str(sample)+'.jpg', im[y:y+h,x:x+w]) # the image will be saved in the given folder\n",
    "        cv2.imshow('Capture', im)\n",
    "\n",
    "    if (cv2.waitKey(1)==ord('x')) or (sample>200):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "recognize=cv2.face.LBPHFaceRecognizer_create()\n",
    "path='data'\n",
    "def getImageWithId(path):\n",
    "    imgpaths=[os.path.join(path,v) for v in os.listdir(path)] # storing the path of all images\n",
    "    image=[]\n",
    "    ids=[]\n",
    "    for x in imgpaths:\n",
    "        gray=Image.open(x).convert('L') # converting image in grayscale\n",
    "        imgnp=np.array(gray, 'uint8') # converting image into array\n",
    "        image.append(imgnp) # adding image matrix in image list\n",
    "        y=int(os.path.split(x)[-1].split(\".\")[1]) # getting the id from the image path\n",
    "        ids.append(y) # adding the id in Id list\n",
    "    return image,ids\n",
    "image,ids=getImageWithId(path)\n",
    "recognize.train(image,np.array(ids))\n",
    "recognize.write('train.yml')\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
